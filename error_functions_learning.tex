%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%\documentclass[pdflatex,sn-mathphys]{sn-jnl}
\documentclass[pdflatex,referee,sn-mathphys]{sn-jnl}

%% \documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[iicol,pdflatex,sn-mathphys]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[sn-standardnature]{sn-jnl}% Standard Nature Portfolio Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%% <additional latex packages if required can be included here>
\usepackage{subcaption}
\usepackage{xspace}
%%%% 

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\newcommand{\ie}{\emph{i.e.}}
\newcommand{\cp}{\textsc{CP}\xspace}
\newcommand{\csp}{\textsc{CSP}\xspace}
\newcommand{\cop}{\textsc{COP}\xspace}
\newcommand{\efsp}{\textsc{EFSP}\xspace}
\newcommand{\efop}{\textsc{EFOP}\xspace}
\newcommand{\cfn}{\textsc{CFN}\xspace}
\newcommand{\cbls}{\textsc{CBLS}\xspace}
\newcommand{\ghost}{\textsc{GHOST}\xspace}
\newcommand{\cppn}{\textsc{CPPN}\xspace}
\newcommand{\icn}{\textsc{ICN}\xspace}

\newcommand{\cproblem}[3]%
{\begin{trivlist}
  \item[]%
    \textbf{Problem:} \textsc{#1}\\
    \textit{Input:} #2\\
    \textit{Question:} #3
  \end{trivlist}%
}

\newcommand{\efopmodel}[4]%
{\begin{trivlist}
  \item[]%
    \textbf{Variables:} #1\\
    \textbf{Domains:} #2\\
    \textbf{Constraints:} #3\\
    \textbf{Objective function:} #4
  \end{trivlist}%
}

\newcommand{\flo}[1]{\textcolor{blue}{\bf Flo: \xspace #1}}
\newcommand{\jf}[1]{\textcolor{red}{\bf JF: \xspace #1}}

\begin{document}

% \title[Interpretable  Error Functions  Learning for  CP]{Interpretable
%   Error Functions Learning for Constraint Programming}

\title[Automatic Error Function Learning with ICN]{Automatic Error Function Learning with Interpretable Compositional Networks}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Florian} \sur{Richoux}}\email{florian@richoux.fr}
\author[2]{\fnm{Jean-FranÃ§ois} \sur{Baffier}}\email{jf@baffier.fr}

\affil*[1]{\orgname{AIST}, \orgaddress{\city{Tokyo}, \country{Japan}}}
\affil[2]{\orgname{IIJ}, \orgaddress{\city{Tokyo}, \country{Japan}}}

%\affil[3]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{610101}, \state{State}, \country{Country}}}

\abstract{   In  Constraint   Programming,  constraints   are  usually
  represented  as predicates  allowing or  forbidding combinations  of
  values.    However,   some   algorithms    can   exploit   a   finer
  representation: error functions.  By  associating a function to each
  constraint type to evaluate the quality of an assignment, it extends
  the    expressiveness    of    regular    Constraint    Satisfaction
  Problem/Constrained  Optimization Problem  formalisms.  Their  usage
  comes with a  price though: it makes  problem modeling significantly
  harder, since users  must provide a set of error  functions that are
  not  always  easy   to  define.   Here,  we  propose   a  method  to
  automatically learn an error function corresponding to a constraint,
  given  its predicate  version only.   This is,  to the  best of  our
  knowledge, the first attempt  to automatically learn error functions
  for hard constraints.  Our method aims to learn error functions in a
  supervised fashion,  trying to reproduce  either the Hamming  or the
  Manhattan distance, by  using a variant of neural  networks we named
  Interpretable Compositional Networks. This  variant allows us to get
  interpretable  results,   unlike  with  regular   artificial  neural
  networks.  We run experiments on 7 different constraints to show its
  versatility.  Experiments  show that our system  can learn functions
  that scale to  high dimensions, and can learn  fairly good functions
  over incomplete  spaces. We also  show that learned  error functions
  can  be  used  efficiently  to represent  constraints  in  different
  classic problems.  }

\keywords{Combinatorial Satisfaction, Combinatorial Optimization, Constraint Programming, Problem Modeling, Error Function, Interpretable Learning}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec:introduction}

Twenty   years  separate   Freuder's  papers   \cite{Freuder1997}  and
\cite{Freuder2018},  both   about  the  grand   challenges  Constraint
Programming  (\cp)  must  tackle  \emph{``to  be  pioneer  of  a  new
  usability    science     and    to    go    on     to    engineering
  usability''}~\cite{Freuder2007}.

To  respond  to   the  lack  of  a  ``Model  and   Run''  approach  in
\cp~\cite{Puget2004,Wallace2003},   several    languages   have   been
developed  since  the  late 2000's,  such  as  ESSENCE~\cite{essence},
XCSP~\cite{XCSP-paper}  or  MiniZinc~\cite{minizinc}.   However,  they
require users to have deep expertise on global constraints and to know
how well  these constraints, and  their associated mechanisms  such as
propagators,  are suiting  the  solver.   We are  still  far from  the
original Holy Grail  of \cp: \emph{``the user states  the problem, the
  computer solves it''}~\cite{Freuder1997}.%% Some progress has been
%% made though, like in automatic problem modeling~\cite{Freuder2018}:
%% one can cite, among other  works, constraint detection described in
%% a natural language~\cite{Kiziltan2016},  automatic constraint model
%% production    from    an    abstract    constraint    specification
%% language~\cite{AMJFH2011}, and  acquiring constraint  networks from
%% examples classified by the user~\cite{Bessiere2017}.

This paper makes a contribution  in automatic \cp problem modeling. We
focus  on Error  Function  Satisfaction and  Optimization Problems  we
defined  in  the  next   section.   Compare  to  classical  Constraint
Satisfaction  and Constrained  Optimization Problems,  they rely  on a
finer structure about  the problem: the cost  functions network, which
is an  ordered structure over  invalid assignments (in our  case) that
some  solvers,  such as  constraint-based  local  search solvers,  can
exploit efficiently to improve the search.

In  this  paper,  we  propose   a  method  to  learn  error  functions
automatically; a direction that, to the best of our knowledge, had not
been explored in Constraint Programming.

\section{Error Function Satisfaction and Optimization Problems}\label{sec:efsp}

Constraint  Satisfaction Problem  (\csp) and  Constrained Optimization
Problem (\cop) are constraint-based  problems defined upon a classical
hard-constraint network,  where constraints can be  seen as predicates
allowing or forbidding some combinations of variable assignments.

Likewise,  Error  Function  Satisfaction  Problem  (\efsp)  and  Error
Function  Optimization Problem  (\efop) are  constraint-based problems
defined upon  a specific hard-constraint network named  cost function
network~\cite{GuidedTour}        or        semi-ring        constraint
network~\cite{handbookCP}.   Both  networks  are  equivalent  for  the
purpose of  this paper: cost  function networks exactly  correspond to
semi-ring   constraint   networks   with  a   totally   ordered   cost
structure~\cite{GuidedTour}.

Constraints    are     then    represented    by     cost    functions
\(f: D_1  \times D_2 \times  \ldots \times D_n \rightarrow  E\), where
\(D_i\) is  the domain of  \(i\)-th variable in the  constraint scope,
\(n\) the number of variables (\ie,  the size of this scope) and \(E\)
the set of possible costs.

A cost function network is a quadruplet \(\langle V, D, F, S \rangle\)
where \(V\) is a  set of variables, \(D\) the set  of domains for each
variable, \ie,  the sets of values  each variable can take,  \(F\) the
set of cost functions and \(S\)  a cost structure. A cost structure is
also a quadruplet \(S = \langle  E, \oplus, \bot, \top \rangle\) where
\(E\)  is the  totally ordered  set  of possible  costs, \(\oplus\)  a
commutative,  associative,  and   monotone  aggregation  operator  and
\(\bot\)  and  \(\top\) are  the  neutral  and absorbing  elements  of
\(\oplus\), respectively.

In  Constraint Programming,  cost  functions are  often associated  to
soft-constraints: they can be interpreted as preferences over valid or
acceptable assignments.  However, this is not necessarily the case: it
actually depends on  the cost structure.  For  instance, the classical
cost structure
\[S_{t/f} = \langle \{true, false\}, \wedge, true, false\rangle\] make
the  cost  function  network  equivalent  to  a  classical  constraint
network, so dealing with hard-constraints.

Here,  we  consider  particular  cost functions  that  also  represent
hard-constraints  only, by  considering  the  additive cost  structure
\(S_+ = \langle \mathbb{R}, +,  0, \infty\rangle\).  The additive cost
structure produces  useful cost  function networks  capturing problems
such as Maximum Probability Explanation (MPE) in Bayesian networks and
Maximum    A   Posteriori    (MAP)   problems    in   Markov    random
fields~\cite{Hurley16}.

We  name {\bf  error  function}  a cost  function  defined  in a  cost
function   network   with   the   additive   cost   structure~\(S_+\).
Intuitively,  error  functions  are  preferences  over  \emph{invalid}
assignments.   Let  \(f_c\)  be   an  error  function  representing  a
constraint \(c\)  and \(\vec x_c\)  an assignment of variables  in the
scope of \(c\).  Then \(f_c(\vec x_c) = 0\) iff \(\vec x_c\) satisfies
the  constraint  \(c\).   For all  invalid  assignments~\(\vec  i_c\),
\(f_c(\vec i_c) > 0\) such that  the closer \(f_c(\vec i_c)\) is to 0,
the closer~\(\vec i_c\) is to satisfy \(c\).

The goal  of this paper  is not to study  the advantages of  such cost
function   networks   over    regular   constraint   networks.    Some
Constraint-Based Local Search methods  such as Adaptive Search exploit
this  structure  efficiently  and show  state-of-the-art  experimental
results,     both     in     sequential~\cite{AS}     and     parallel
solving~\cite{caniou2015constraints}.  Such  question would  deserve a
deep investigation which  is out of the scope of  this paper. However,
we can  give a short  illustration of  the advantage of  cost function
networks over regular constraint networks. Figure~\ref{fig:landscapes}
shows  the search  landscapes of  the same  constraint network  from a
regular constraint  network (Figure~\ref{fig:csp_landscape})  and cost
function network (Figure~\ref{fig:efsp_landscape})  point of view. The
network  is  composed  of   the  constraints  AllDifferent\((x,  y)\),
\(x   \leq   y\)   and   \(x+2y=6\).    Error   functions   used   for
Figure~\ref{fig:efsp_landscape} have been learned  with our system. We
can see that  the \csp landscape is mostly composed  of large plateaus
with an error  measure (the number of violated  constraints) between 0
and 2.   On the other  hand, the \efsp  landscape is more  convex with
slopes  toward the  solution, with  a broader  scope of  error values,
between 0 and 6, allowing richer comparisons of variable assignments.

\begin{figure}[h]
	\centering
	\begin{subfigure}[t]{0.49\linewidth}
		\centering
    \includegraphics[width=\linewidth]{./figs/csp_landscape_complex_zero_big}
		\caption{\csp landscape}\label{fig:csp_landscape} 
	\end{subfigure}
  \hfill
	\begin{subfigure}[t]{0.49\linewidth}
		\centering
    \includegraphics[width=\linewidth]{./figs/efsp_landscape_complex_zero_big}
		\caption{\efsp landscape}\label{fig:efsp_landscape} 
	\end{subfigure}
  \caption{Search landscapes of a small constraint network.}
  \label{fig:landscapes}
\end{figure}

The  term  ``error   function''  has  been  used   in  the  Constraint
Programming literature in the same sense as in this paper.  Borning et
al.~\cite{Borning94} are the  first, to the best of  our knowledge, to
use this  term. It also  appears in the constraint-based  local search
literature,  like in  Codognet et  al.~\cite{AS} describing  the local
search algorithm  Adaptive Search.   We can  also find  the equivalent
term   ``penalty   function''~\cite{Galinier04}   for   local   search
algorithms in  Constraint Programming.  However, penalty  function can
also refers to functions representing soft-constraints in Mathematical
Programming~\cite{MezuraMontes2011}.   Therefore, to  avoid confusions
with  cost functions  or  penalty functions  for soft-constraints,  we
opted for the name ``error function''.

Let \(\vec  x\) be a variable  assignment, and denote by  \(\vec x_c\)
the  projection  of \(\vec  x\)  over  variables  in  the scope  of  a
constraint \(c\).  We can now define the \efsp and \efop problems.

\cproblem%
{Error Function Satisfaction Problem}%
{ A cost function network \(\langle V, D, F, S_+ \rangle\).}%
{ Does   a   variable   assignment   \(\vec   x\)   exist   such   that
  \(\forall f_c \in F,\ f_c(\vec x_c)=0\) holds?}%

\cproblem%
{Error Function Optimization Problem}%
{ A  cost function  network \(\langle  V, D,  F, S_+  \rangle\) and  an
  objective function \(o\).}%
{ Find a  variable assignment \(\vec  x\) maximizing or  minimizing the
  value        of        \(o(\vec         x)\)        such        that
  \(\forall f_c \in F,\ f_c(\vec x_c)=0\) holds.}%

Thanks to their constraint structure,  problems modeled by an \efsp or
an \efop can be solved by constraint-based local search solvers faster
than if  they were  modeled by  a \csp or  a \cop.   Or with  the same
computation  budget,  a  solver  could solve  larger  \efsp  or  \efop
problems. However,  we do  not obtain  this gain for  free: this  is a
trade with modeling simplicity. Indeed, it  is not always easy to find
good  error  functions to  describe  constraints.%    For instance,  the
% function \(f(x,y) = |x-y|\) seems intuitive to describe the constraint
% \(x=y\), but  is actually a  poor choice since all  invalid assignment
% requires to change one variable only.  This would not fit Local Search
% algorithms well.   Moreover, it is not  trivial how to define  it over
% higher dimensions (for instance, for the constraint \(x=y=z\)).

This paper focuses on this  ``easy-to-use'' problem and proposes a way
to  automatically  learn error  functions.   Users  provide the  usual
constraint  network  \(\langle V,  D,  C  \rangle\), and  our  systems
computes      the      equivalent     cost      function      networks
\(\langle V, D, F, S_+  \rangle\). Learned functions composing the set
\(F\) are independent of the number of variables in constraints scope,
and are expressed in an  interpretable way: users can understand these
functions and  easily modify them at  will.  This way, users  can have
the power of \efsp and \efop with the same modeling effort as for \csp
and \cop.

\section{Related works}\label{sec:related_works}

This  work  belongs to  one  of  the  three directions  identified  by
Freuder~\cite{Freuder2007}:   \emph{Automation},   \ie,   ``automating
efficient and  effective modeling and  solving''.  To the best  of our
knowledge, few efforts have been done on the modeling side.

Another  of  these  three  directions which  is  slightly  related  is
\emph{Acquisition} described  by Freuder to be  ``acquiring a complete
and correct representation of  real problems''.  Remarkable efforts on
this topic  have been done  by Bessiere's research team,  for instance
with  constraints learning  by  induction from  positive and  negative
examples~\cite{Bessiere05},   with   interactive  queries   asked   to
users~\cite{Bessiere07},  and with  constraint  network learning  also
through with interactive queries~\cite{Bessiere13}.

Model Seeker~\cite{Beldiceanu12}  is a passive learning  system taking
positive  examples  only, which  are  certainly  easier for  users  to
provide.   It transforms  examples  into data  adapted  to the  Global
Constraint   Catalog~\cite{catalog},   then  generate   and   simplify
candidates by eliminating dominated ones. Model Seeker is particularly
efficient  to find  a good  inner structure  of the  target constraint
network.

Teso~\cite{Teso19}  gives a  good survey  on Constraint  Learning with
this  interesting remark:  ``A major  bottleneck of  [constraint-based
problem  modeling] is  that obtaining  a formal  constraint theory  is
non-obvious: designing an appropriate, working constraint satisfaction
or optimization  problem requires both domain  and modeling expertise.
For this reason, in  many cases a modeling expert is  hired and has to
interact with domain expert to  acquire informal requirements and turn
them into  a valid constraint  theory.  This process can  be expensive
and time-consuming.''

We can  consider that Constraint Acquisition,  or Constraint Learning,
focuses on modeling expertise and puts domain expertise on background:
users  would not  be able  to understand  and modify  a learned  model
without the  help of a modeling  expert. The goal of  these systems is
mainly to simplify the interaction between the domain and the modeling
experts.

Our  work  is  taking  the  opposite direction:  we  focus  on  domain
expertise and put modeling expertise  on background.  With our system,
users always have the  control over constraints' representation, which
can  be  modified  at  will  to fit  needs  related  to  their  domain
expertise.   \emph{Constraint Implementation  Learning}  is what  best
describes this research topic.

\section{Method design}\label{sec:method_design}

The main result of this paper  is to propose a method to automatically
learn an error function representing  a constraint, to make easier the
modeling of \efsp/\efop.   We are tackling a  regression problem since
the  goal is  to find  a function  that outputs  a target  value. More
specifically,  looking for  the  model of  a function  in  a space  of
mathematical representation  is a  symbolic regression  problem.  Such
problems  are often  handled by  Genetic Programming  methods, but  we
explain  in Section~\ref{subsec:learning}  why we  do not  use Genetic
Programming to learn error functions in this work.

In this paper, we denote by \textbf{method} the methodology we propose
to learn error function, and  by \textbf{system} the implementation of
our method.  Before diving into the description of our method, we need
to introduce some essential notions.

\subsection{Definitions}\label{subsec:definitions}

We propose a method to automatically  learn an error function from the
\emph{concept}  of   a  constraint.   As  described   in  Bessiere  et
al.~\cite{Bessiere2017},  the \textbf{concept}  of a  constraint is  a
Boolean  function  that,  given  an  assignment  \(\vec  x\),  outputs
\emph{true} if  \(\vec x\) satisfies the  constraint, and \emph{false}
otherwise. Concepts  are the  predicate representation  of constraints
referred at the beginning of Section~\ref{sec:efsp}.

Our method learns  error functions in a  supervised fashion, searching
for  a  function  computing  either the  \emph{Hamming  cost}  of  the
\emph{Manhattan cost} of each assignment. The \textbf{Hamming cost} of
an  assignment  \(\vec x\)  is  the  minimum  number of  variables  in
\(\vec x\)  to reassign  to get a  \textbf{solution}, \ie,  a variable
assignment satisfying  the considered constraint.  In  other words, it
is the Hamming  distance from \(\vec x\) to its  closest solution.  If
\(\vec  x\)  is  a  solution,  then   its  Hamming  cost  is  0.   The
\textbf{Manhattan cost}  of an  assignment \(\vec  x\) is  the minimum
number of  value incrementations or  decrementations in \(\vec  x\) to
perform to get  a solution.  It corresponds to  the Manhattan distance
from \(\vec x\)  to its closest solution. As for  the Hamming cost, if
\(\vec x\) is a solution, its Manhattan cost is 0.

Given the  number of variables of  a constraint and their  domain, the
\textbf{constraint   assignment  space}   is   the   set  of   couples
\((\vec  x, b)\)  where  \(\vec x\)  is an  assignment  and \(b\)  the
Boolean output of the concept  applied on \(\vec x\).  Such constraint
assignment spaces  can be  generated from  concepts. These  spaces are
said to be \textbf{complete} if and  only if they contain all possible
assignments, \ie, all combinations of  possible values of variables in
the scope  of the constraint,  given their domain.   Otherwise, spaces
are said to be \textbf{incomplete}.

In  this work,  we consider  an error  function to  be a  (non-linear)
combination of elementary operations.  Complete spaces are intuitively
good training sets  since it is easy to compute  the exact Hamming and
Manhattan costs of their elements.   We also consider assignments from
incomplete spaces  where their Hamming  and Manhattan costs  have been
approximated  regarding  a  subset  of  solutions  in  the  constraint
assignment space, in case their exact formulas are unknown.

\subsection{Main result}\label{subsec:main_result}

Our  method learns  error  functions as  a  non-linear combination  of
elementary   operations    and   lies    on   a   model    we   called
\textbf{Interpretable  Compositional Network}  (\icn).  An  \icn is  a
directed acyclic graph  composed of $k$ independent  sets organised in
such  a  way that  vertices  of  an  independent set  are  exclusively
connected  to  all  vertices  of  a  unique  independent  set  in  the
graph. Thus, if we abstract each  independent set by a vertex, then we
obtain a directed linear graph.

\(\icn\)s are  networks in the  graph theory  way, \ie, a  graph where
vertices or arcs  have attributes.  In an \icn,  vertices are actually
elementary operations,  and arcs  represent the  possible combinations
between these elementary operations.

In its  shape, an \icn looks  like a neural network:  the hierarchical
organisation  between  independent  sets exactly  corresponds  to  the
hierarchical structure of  layers of neurons. Due  to this similarity,
we call  \emph{layers} the independent  sets within an  \icn. However,
the similarity  with neural networks  stops here: the  main difference
between \(\icn\)s and neural networks  it that there are no activation
functions  within  \(\icn\)s (the  elementary  operation  of a  vertex
cannot  be considered  to be  an activation  function). A  second main
difference is  that \(\icn\)s do  not have weights on  arcs connecting
two vertices.   We first introduced \(\icn\)s  in a poster paper  as a
variant of neural  networks~\cite{richoux2021gecco}.  Although \icn is
deeply inspired from a variant of  neural networks, the correct way to
interpret our  model is  to see  it as  a particular  directed acyclic
graph.

In this paper, our \(\icn\) model  is composed of four layers, each of
them having a specific purpose and  composed of vertices with a unique
operation for each. Learning an error function boils down to selecting
which vertices  of the  network would  be part  of the  composition of
elementary operations.

Here is our method workflow in 4 points:
\begin{enumerate}
\item     Users    provide     a     regular    constraint     network
  \(\langle  V, D,  C  \rangle\)  where \(C\)  is  a  set of  concepts
  representing constraints.
\item For  each constraint concept  \(c\), we generate its  \icn input
  space \(X\),  which is  either a  complete or  incomplete constraint
  assignment space.  Those input spaces are our training sets.  If the
  space  is complete,  then the  Hamming and  Manhattan costs  of each
  assignment  can  be pre-computed  before  learning  our \icn  model.
  Otherwise,  the  incomplete  space  is composed  of  randomly  drawn
  assignments and only an approximation of their Hamming and Manhattan
  costs can be pre-computed.
\item We learn the composition of elementary operations modeled by our
  \icn in a supervised fashion, with the following loss function:
  \begin{equation}\label{eq:loss}
    loss = Min\left(Hamming_{diff}, Manhattan_{diff}\right) + Regularization
  \end{equation}
  with 
  \begin{align}
    Hamming_{diff} &= \frac{\sum_{\vec x \in X} \mid ICN(\vec x) -
                       Hamming(\vec x)\mid}{n} \nonumber \\
    Manhattan_{diff} &= \frac{\sum_{\vec x \in X} \mid ICN(\vec x) -
                         Manhattan(\vec  x)\mid}{n~\times (\mid  D\mid - 1)} \nonumber \\
    Regularization &= 0.9  \times  \frac{\text{Number  of  selected  vertices}}{\text{Total number of vertices}}
  \end{align}
  where \(X\) is the constraint assignment space, \icn(\(\vec x\)) the
  output  of the  \icn model  giving  \(\vec x  \in X\)  as an  input,
  Hamming(\(\vec  x\))  and  Manhattan(\(\vec  x\))  respectively  the
  pre-computed  Hamming  and  Manhattan  costs  of  \(\vec  x\)  (only
  approximated  if \(X\)  is  incomplete), and  a regularization  term
  between  0 and  0.9  to  favor short  \(\icn\)s,  \ie,  with as  few
  elementary  operations  as  possible.   To make  a  fair  comparison
  between the Hamming and Manhattan costs, we normalize these costs in
  \([0,1]\) by dividing  the Hamming difference with  the number \(n\)
  of variables  in the scope  of the  constraint, and by  dividing the
  Manhattan  difference with  \(n\) times  the difference  between the
  maximal  value and  the minimal  value  in the  domain of  variables
  (corresponding  to the  cardinality of  the  domain minus  1 in  our
  context).
\item We have hold-out test sets of assignments from larger dimensions
  to evaluate the quality of our learned error functions.
\end{enumerate}

% Notice we also have a hold-out validation set to fix the values of our
% hyperparameters, as described in Section~\ref{sec:ga}.

% Notice we  do not have  any validation sets  since we use  the default
% value of the parameters.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./figs/model_nn}
  \caption{Our 4-layer network. Layers with blue vertices have mutually exclusive operations.}
  \label{fig:model}
\end{figure}

Figure~\ref{fig:model}   is   a   schematic  representation   of   our
network. It  takes as input an  assignment of \(n\) variables,  \ie, a
vector    of    \(n\)    integers.    The    first    layer,    called
\textbf{transformation  layer},  is   composed  of  18  transformation
operations, each of  them applied element-wise on each  element of the
input vector.   This element-wise computation property  is what allows
our model to be able to compute  the error function of a constraint of
an arbitrary size,  \ie, with an arbitrary number of  variables in the
constraint  scope.  This  is  a very  powerful  feature  that  enables
learning  error functions  over a  small constraint  assignment spaces
that scale to larger spaces.

Such transformation  operations are  for instance the  maximum between
the  \(i\)-th and  \(i+1\)-th elements  of  the input  vector, or  the
number of  \(j\)-th elements of  the vector smaller than  the \(i\)-th
element such  that \(j >  i\) holds.  This  layer is composed  of both
linear and non-linear  operations.  If an operation  is selected (\ie,
it has an outgoing  weight equals to 1), it outputs  a vector of \(n\)
integers.

\begin{example}
  Consider one of our  18 transformation operations: ``\emph{Number of
    $x[j]$ such that  \(j < i\) and $x[i]=x[j]$},''  with \(x[i]\) and
  \(x[j]\)  respectively  the  \(i\)-th  and  \(j\)-th  value  of  the
  assignment \(\vec x\).  Giving the assignment \((3,1,3,4,3,1,2)\) as
  input,   this   transformation    operation   outputs   the   vector
  \((0,0,1,0,2,1,0)\).
\end{example}

If \(k\) transformation  operations are selected, then  the next layer
gets \(k\)  vectors of  \(n\) integers  as input.   This layer  is the
\textbf{arithmetic layer}.  Its  goal is to apply  a simple arithmetic
operation in a  component-wise fashion on all \(i\)-th  element of our
\(k\)  vectors  to get  one  vector  of  \(n\)  integers at  the  end,
combining  previous  transformations into  a  unique  vector. We  have
considered  only  2  arithmetic   operations:  the  addition  and  the
multiplication.

\begin{example}
  Consider the addition as the arithmetic operation, and as inputs the
  two  vectors  \((0,0,1,0,2,1,0)\)   and  \((2,0,1,0,2,0,0)\).  Then  the
  arithmetic layer outputs the vector \((2,0,2,0,4,1,0)\).
\end{example}

The output of the arithmetic layer is given to the \textbf{aggregation
  layer}. This layer crunches the  whole vector into a unique integer.
At  the moment,  the aggregation  layer is  composed of  2 operations:
\emph{Sum} computing the sum of input values and \emph{\(Count_{>0}\)}
counting the number of input values strictly greater than 0.

\begin{example}
  Consider  the aggregation  operation \emph{\(Count_{>0}\)}  applied on
  \((2,0,2,0,4,1,0)\). Then, the aggregation  layer outputs \(4\), since 4
  values in the input are strictly greater than 0.
\end{example}

Finally, the computed scalar  is transmitted to the \textbf{comparison
  layer}  with 9  operations.  Examples  of these  operations are  the
identity,  or  the   absolute  value  of  the  input   minus  a  given
parameter. This  layer compares its  input with an  external parameter
value, or the number of variables  of the problem, or the domain size,
among others.

\begin{example}
  Consider             the            comparison             operation
  \emph{\(Max(0\mathrel{,}\  input -  parameter)\)}.   Assume that  we
  have the parameter \(p=1\) and  \(4\) as input. The comparison layer
  outputs \(3\).
\end{example}

All elementary operations  in our model are generic: we  do not choose
them to fit one or  several particular constraints.  The complete list
of elementary operations in our \icn model is given in appendix.

Although  an in-depth  study of  the elementary  operations properties
would be interesting, this is out of the scope of this paper: its goal
is to show  that learning interpretable error functions  via a generic
\icn is possible. There is no reason  to reduce \icn to its current 31
elementary operations  or even a 4-layer  architecture.  Such elements
can be changed by users to best fit their needs.

To  have  simple   models  of  error  functions,   operations  of  the
arithmetic, the  aggregation, and  the comparison layers  are mutually
exclusive, meaning that  precisely one operation is  selected for each
of  these layers.   However, many  operations from  the transformation
layer can be selected to compose the error function. This allows us to
have  a very  comprehensible combination  of elementary  operations to
model  an error  function, making  it readable  and intelligible  by a
human being.  For instance, the  most frequenly learned error function
is
\(Count_{>0}\big(\#\{j\ \mid\ x[j]=x[i] \text{ and } j>i\}\big)\)
for AllDifferent, and \(\mid \big(\sum^{n}_{i=1} x[i]\big) - p\mid\)
for  LinearSum,  with  \(p\)  the  right hand  side  constant  of  the
equation. Thus, once the model of  an error function is learned, users
have  the choice  to  run the  network in  a  feed-forward fashion  to
compute  the error  function,  or  to re-implement  it  directly in  a
programming  language.   Users  can  use  our  system  to  find  error
functions  automatically, but  they  can  also use  it  as a  decision
support system to find promising  error functions that they may modify
and adapt by hand.

\subsection{Learning \efsp/\efop models through an \efop model}\label{subsec:learning}

As written in the introduction of Section~\ref{sec:method_design}, our
error function  learning problem is  a symbolic regression  problem, a
family of problems usually tackled through Genetic Programming.

The issue with  learning error functions using  Genetic Programming is
that,  in addition  of  having  a huge  search  space of  mathematical
representations, we cannot guaranty  learning error functions that are
independent from the input size, \ie,  from the number of variables in
the scope of the target constraint. This property is mandatory to have
a unique function  able to compute the error of  a given constraint on
3, 30 or 300 variables.  This property also allows us to quickly learn
error functions over small constraint scopes  in order to use them for
computing the error of their constraints over large scopes.

What we  do in this work  is actually solving a  \emph{biased symbolic
  regression problem}, where  the bias is induced by  the structure of
the  \icn we  provide.  The  architecture of  an \icn  to learn  error
functions forces their shape and  drastically reduces the search space
of mathematical  representations.  More  importantly, it  enforces the
input size independence property.

Learning an  error function via  an \icn corresponds to  selecting the
right vertices  in such a way  that it both satisfies  some conditions
and minimizes the difference with the Hamming or Manhattan cost on the
constraint  assignment  space  used  as a  training  set.   Therefore,
learning  an   error  function   is  simultaneously   a  combinatorial
optimization  problem itself,  and a  regression problem  that can  be
tackled      by     supervised      learning,     as      shown     in
Section~\ref{subsec:main_result}.

This combinatorial optimization problem can  actually be modeled as an
\efop. We propose the following model:%
\efopmodel%
{One variable for each vertex in the \icn.}%
{Boolean  domain  \(\{0,1\}\)  for each  variable,  representing  their
  selection.}%
{Mutual exclusion, No empty layer, Parameter-specific operations.}%
{Loss function given by Equation~\ref{eq:loss}.}%

The ``Mutual exclusion''  constraint is applied on the  three last layers,
\ie, the  arithmetic, the  aggregation and  the comparison  layers. It
ensures  that  exactly   one  vertex  in  each  of   these  layers  is
selected.  This simply corresponds to the linear equation \(\sum_{v \in layer} v = 1\).
We use \(\mid  1 - \sum_{v \in  layer} v \mid\) as  the error function
for this contraint.

The ``No empty layer'' constraint only concerns the first layer, where
at least  one vertex need to  be selected. This can  be represented by
the  linear inequation  \(\sum_{v \in  layer} v  \geq 1\)  and can  be
represented by the error function \(Max(0, 1 - \sum_{v \in layer} v)\).

Some  elementary operations  within our  \icn involve  the value  of a
parameter \(p\)  in their  computation. Indeed, some  constraints need
some parameters  to be defined, such  as the linear equation  with the
constant   at   the   right   hand  side   of   the   equation.    The
``Parameter-specific operations'' constraint  enforces that elementary
operations can be part of the  operation combination if and only if we
are dealing with  a constraint involving one or  some parameters. This
constraint is easily  expressed as follows: considering  that \(m\) is
the number  of selected  parameter-specific elementary  operations, if
the  target constraint  contains some  parameters, then  we must  have
\(m \geq  1\), otherwise \(m =  0\) must hold. The  error function for
this constraint is then a combination of both previous error functions
regarding if the target constraint  contains at least one parameter or
not.

% \section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval 
% \item Consent to participate
% \item Consent for publication
% \item Availability of data and materials
% \item Code availability 
% \item Authors' contributions
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

% %%===================================================%%
% %% For presentation purpose, we have included        %%
% %% \bigskip command. please ignore this.             %%
% %%===================================================%%
% \bigskip
% \begin{flushleft}%
% Editorial Policies for:

% \bigskip\noindent
% Springer journals and proceedings: \url{https://www.springer.com/gp/editorial-policies}

% \bigskip\noindent
% Nature Portfolio journals: \url{https://www.nature.com/nature-research/editorial-policies}

% \bigskip\noindent
% \textit{Scientific Reports}: \url{https://www.nature.com/srep/journal-policies/editorial-policies}

% \bigskip\noindent
% BMC journals: \url{https://www.biomedcentral.com/getpublished/editorial-policies}
% \end{flushleft}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%


\bibliography{error_functions_learning}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%% Default %%
%%\input sn-sample-bib.tex%


\begin{appendices}

\section{List of elementary operations}

\subsection{Transformation layer}

\begin{itemize}
\item Identity
  \begin{displaymath}
    id(x[i]) := x[i]
  \end{displaymath}

\item Number of elements on the right equals to \(x[i]\)
  \begin{displaymath}
    Count_{=}^{r}(x[i]) := \#\{x[j] \ \mid\  j>i\ \wedge\ x[j]=x[i]\}
  \end{displaymath}

\item Number of elements on the right smaller than \(x[i]\)
  \begin{displaymath}
    Count_{<}^{r}(x[i]) := \#\{x[j] \ \mid\  j>i\ \wedge\ x[j]<x[i]\}
  \end{displaymath}

\item Number of elements on the right greater than \(x[i]\)
  \begin{displaymath}
    Count_{>}^{r}(x[i]) := \#\{x[j] \ \mid\  j>i\ \wedge\ x[j]>x[i]\}
  \end{displaymath}

\item Number of elements on the left equals to \(x[i]\)
  \begin{displaymath}
    Count_{=}^{l}(x[i]) := \#\{x[j] \ \mid\  j<i\ \wedge\ x[j]=x[i]\}
  \end{displaymath}

\item Number of elements on the left smaller than \(x[i]\)
  \begin{displaymath}
    Count_{<}^{l}(x[i]) := \#\{x[j] \ \mid\  j<i\ \wedge\ x[j]<x[i]\}
  \end{displaymath}

\item Number of elements on the left greater than \(x[i]\)
  \begin{displaymath}
    Count_{>}^{l}(x[i]) := \#\{x[j] \ \mid\  j<i\ \wedge\ x[j]>x[i]\}
  \end{displaymath}

\item Number of elements equals to \(x[i]\) + param
  \begin{displaymath}
    Count_{=+p}(x[i]) := \#\{x[j] \ \mid\  x[j] = x[i] + param\}
  \end{displaymath}

\item Number of elements smaller than \(x[i]\) + param
  \begin{displaymath}
    Count_{<+p}(x[i]) := \#\{x[j] \ \mid\  x[j] < x[i] + param\}
  \end{displaymath}

\item Number of elements greater than \(x[i]\) + param
  \begin{displaymath}
    Count_{>+p}(x[i]) := \#\{x[j] \ \mid\  x[j] > x[i] + param\}
  \end{displaymath}

\item Max(0, \(x[i]\) - param)
\item Max(0, param - \(x[i]\))
\item Max(0, \(x[i] - x[i+1]\) )
\item Max(0, \(x[i+1] - x[i]\) )
\item Number of elements equals to \(x[i]\)
  \begin{displaymath}
    Count_{=}(x[i]) := \#\{x[j] \ \mid\  x[j] = x[i]\}
  \end{displaymath}

\item Number of elements smaller than \(x[i]\)
  \begin{displaymath}
    Count_{<}(x[i]) := \#\{x[j] \ \mid\  x[j] < x[i]\}
  \end{displaymath}

\item Number of elements greater than \(x[i]\)
  \begin{displaymath}
    Count_{>}(x[i]) := \#\{x[j] \ \mid\  x[j] > x[i]\}
  \end{displaymath}

\item Number of elements greater than or equals to \(x[i]\) AND less than or equals to \(x[i]\) + param 
  \begin{displaymath}
    Count_{>=<+p}(x[i]) := \#\{x[j] \ \mid\ x[j] \geq x[i] \wedge x[j] \leq x[i] + param\}
  \end{displaymath}

\end{itemize}

\subsection{Arithmetic layer}

\begin{itemize}
\item Sum of the \(i\)-th element of each vector \(\vec x_j\): \(\forall i \in \{1,n\} \sum_{j=1}^k x_j[i]\)
\item Product of the \(i\)-th element of each vector \(\vec x_j\): \(\forall i \in \{1,n\} \prod_{j=1}^k x_j[i]\)
\end{itemize}

\subsection{Aggregation layer}

\begin{itemize}
\item \(\sum_{i=1}^n x[i]\)
\item \(Count_{>0}(\vec x) := \#\{x[i] \mid x[i] > 0\}\)
\end{itemize}

\subsection{Comparison layer}

\begin{itemize}
\item \(id(x) = x\)
\item \(\mid x - param\mid \)
\item \(Max( 0, param - x )\)
\item \(Max( 0, x - param )\)
\item \(Euclidian_p(x)\) := If(x = param) then 0 else 1 + \(\frac{\mid x - param\mid }{maximal\ domain\ size}\)
\item \(Euclidian(x)\) := If(x = 0) then 0 else 1 + \(\frac{x}{maximal\ domain\ size}\)
\item \(\mid\) x - number of variables\(\mid\)
\item Max( 0, number of variables - x )
\item Max( 0, x - number of variables )
\end{itemize}

%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\end{appendices}

\end{document}
